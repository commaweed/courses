# docker course

# get the install script from get.docker.com and execute it
curl -fsSL get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# add user to docker group (relog for it to take effect) 
#   - gives user ability to run a docker container later that could have root permission on the host
#   - redhat won't work with this option - you have to be root
#   - other than that, docker generally needs to run as root
sudo usermod -aG docker me

# need docker machine and compose tools as well
# you get these on docker's website in the documentation area not in the store

# install docker machine
base=https://github.com/docker/machine/releases/download/v0.14.0 &&
curl -L $base/docker-machine-$(uname -s)-$(uname -m) >/tmp/docker-machine &&
sudo install /tmp/docker-machine /usr/local/bin/docker-machine
docker-machine version

# install docker compose
sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose version

# optionally install command-completion for docker compose
sudo yum -y install bash-completion
https://docs.docker.com/compose/completion/
sudo curl -L https://raw.githubusercontent.com/docker/compose/1.21.2/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose
https://docs.docker.com/machine/completion/
sudo curl -L https://raw.githubusercontent.com/docker/machine/v0.14.0/contrib/completion/bash/docker-machine.bash -o /etc/bash_completion.d/docker-machine

# udemy course code
git clone https://github.com/BretFisher/udemy-docker-mastery.git

# start and check the docker daemon service
sudo systemctl start docker
sudo systemctl status docker

# instructor website
www.bretfisher.com/shell/

# download the nginx web server docker image and run it as a container, opened port 80 on the host IP, then routes that traffic to the container IP on port 80 in the container
docker container run --publish 80:80 nginx
# then change to browser and type localhost/
# run in background, add --detach
docker container run --publish 80:80 --detach nginx
# run with your own name
docker container run --publish 80:80 --detach --name webhost nginx

# see a listing of containers
docker container ls 
docker container ls -a
docker ps

# see logs
docker container logs webhost

# see processes running in a container
docker container top webhost

# remove some containers
docker container rm x y z

# start up a mongo database using docker image/container
docker run --name mongo -d mongo
docker top mongo

# starting three servers on 3 different containers
docker container run --publish 80:80 --detach --name nginx nginx
docker container run --publish 8080:80 --detach --name httpd httpd
docker container run --publish 3306:3306 --detach --env MYSQL_RANDOM_ROOT_PASSWORD=yes --name mysql mysql
# use docker container logs mysql to see the password
# alternatives
docker container run -d -p 3306:3306 --name db -e MYSQL_RANDOM_ROOT_PASSWORD=yes mysql 
# look for GENERATED ROOT PASSWORD: bo0Lae4aecha2tahpha8ooyikei6noeh
curl localhost # get back nginx response
curl localhost:8080 # get httpd response

# and one for elastic search
docker container run -d -p 9200:9200 --name elasticsearch elasticsearch
docker container run -d -p 5601:5601 --name kibana kibana 
curl 127.0.0.1:9200

# network commands
# show networks:
docker network ls
# inspect a network
docker network inspect
# create a network (--driver <-- default is bridge)
docker network create --driver
-> docker network create my_app_net
-> docker container run -d --name new_nginx --network my_app_net nginx
# attach a network to container (dynamically creates a NIC in a container on an existing virtual network)
docker network connect
-> docker network connect --help
-> docker network connect <new> <orginal>
   docker network connect 01ce8cb64a32 d78dd2559775 # this could put your container on 2 networks 
# detach a network from container
docker network disconnect
docker network disconnect 01ce8cb64a32 d78dd2559775 

# bridge network
# the default network that bridges through the NAT firewall to the physical network that the host is connected to
# Note: it does not have the DNS server built into it by default so you can use the --link to link to another container (easier to create a new network for your app)
# host network
# a special network that skips the virtual networking of docker and attaches the container directly to the host interface, but at a cost of security (but can improve performance of high-throughput)
# none network
# equivalent of having an interface on the computer that is not attached to anything

# cannot rely on IP addresses for containers to talk to each other (use DNS naming instead) - docker uses the container name as equivalent of a host name
docker container run -d --name my_nginx --network my_app_net nginx
docker container exec -it my_nginx ping new_nginx # DNS resolution works; they are on same virtual network and can ping each other

# example cli app testing curl -version
docker container run -it --name testcentos --rm centos:7 bash 
docker container run -it --name testubuntu --rm ubuntu:14.04 bash

# =======================================================================================
# networking examples
# =======================================================================================

# in docker group; sudo not needed (some systems won't allow it -- need to be root)
[me:~/data/courses]$ groups
me docker vboxsf

# containers with their auto-generated names
[me:~/data/courses]$ docker container list --no-trunc --format 'table {{.Image}}\t{{.Names}}\t{{.Command}}'
IMAGE                   NAMES               COMMAND
landoop/fast-data-dev   eager_rosalind      "/usr/bin/dumb-init -- bash"
landoop/fast-data-dev   gifted_jones        "/usr/bin/dumb-init -- bash"

# listing host to container ports for a particular container
[me:~/data/courses]$ docker container port lucid_nightingale
8082/tcp -> 0.0.0.0:8082
8083/tcp -> 0.0.0.0:8083
9092/tcp -> 0.0.0.0:9092
2181/tcp -> 0.0.0.0:2181
3030/tcp -> 0.0.0.0:3030
8081/tcp -> 0.0.0.0:8081

# container'''s internal IP address for the virtual network it is on
[me:~/data/courses]$ docker container inspect --format '''{{ .NetworkSettings.IPAddress }}' lucid_nightingale
172.17.0.2

# host and docker networks
[me:~/data/courses]$ ifconfig
docker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
   inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
   inet6 fe80::42:d1ff:fe0f:1722  prefixlen 64  scopeid 0x20<link>
   ether 02:42:d1:0f:17:22  txqueuelen 0  (Ethernet)
   RX packets 6579  bytes 3911139 (3.7 MiB)
   RX errors 0  dropped 0  overruns 0  frame 0
   TX packets 13288  bytes 2253533 (2.1 MiB)
   TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

enp0s3: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
   inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255
   inet6 fe80::b021:62b9:a815:1c8d  prefixlen 64  scopeid 0x20<link>
   ether 08:00:27:35:c6:d4  txqueuelen 1000  (Ethernet)
   RX packets 1564876  bytes 2013272742 (1.8 GiB)
   RX errors 0  dropped 0  overruns 0  frame 0
   TX packets 260374  bytes 31774874 (30.3 MiB)
   TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

# showing all of the networks that have been created in docker (bridge is default == docker0 above)
# --network bridge --> default docker virtual network which is NAT'ed behind the Host IP
[me:~/data/courses]$ docker network ls
   NETWORK ID          NAME                DRIVER              SCOPE
   dfc440a8cb5d        bridge              bridge              local
   406dbffe9820        host                host                local
   1241cf65cdb7        none                null                local

# showing info about the bridge network; it also shows the containers attached to it
[me:~/data/courses]$ docker network inspect bridge
[
   {
      "Name": "bridge",
      "Id": "dfc440a8cb5d3ec0986298ed5ec45e1476d0f85365b00d8113475d788f421355",
      "Created": "2018-06-01T18:28:49.304733642-04:00",
      "Scope": "local",
      "Driver": "bridge",
      "EnableIPv6": false,
      "IPAM": {
      "Driver": "default",
      "Options": null,
      "Config": [
         {
            "Subnet": "172.17.0.0/16",
            "Gateway": "172.17.0.1"
         }
      ]
   },
      "Internal": false,
      "Attachable": false,
      "Ingress": false,
      "ConfigFrom": {
      "Network": ""
   },
      "ConfigOnly": false,
      "Containers": {
      "1e9b894fcb4e895ecd5cbe6057a91878575ca9c3f42eca90972f1b27b4602d8b": {
         "Name": "lucid_nightingale",
         "EndpointID": "ffe18c18cdde74bca69f85497a3932edda7c5d3f3438e25be386c13510e62f16",
         "MacAddress": "02:42:ac:11:00:02",
         "IPv4Address": "172.17.0.2/16",
         "IPv6Address": ""
      }
   },
      "Options": {
      "com.docker.network.bridge.default_bridge": "true",
      "com.docker.network.bridge.enable_icc": "true",
      "com.docker.network.bridge.enable_ip_masquerade": "true",
      "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",
      "com.docker.network.bridge.name": "docker0",
      "com.docker.network.driver.mtu": "1500"
   },
      "Labels": {}
   }
]



# you can create your own - creates a new virtual network with a driver of bridge (default driver)
# default bridge DRIVER is a built-in (or optional 3rd party extension) that gives you virtual network features, such as subnet, etc.
#     default doesn't have any of the advanced features such as overlay networks that allow private networking between hosts
[me:~/data/courses]$ docker network create my_test_network
8d5303842d31f24e3bc12aa3b5022603d85547a9ee85548a4c01f9a71b7cf840
[me:~/data/courses]$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
dfc440a8cb5d        bridge              bridge              local
406dbffe9820        host                host                local
8d5303842d31        my_test_network     bridge              local
1241cf65cdb7        none                null                local

[me:~/data/courses]$ docker network create --help

# can do the --network option when we create a container and assign it to our new network (or to host or none - bridge is default)
# using "--network host" will gain performance by skipping virtual networks but sacrifices security of container model
# using "--network none" removes the host nic ("enp0s3") and only leaves you with localhost interface in container
[me:~/data/courses]$ docker container run -d --name new_nginx --network my_test_network nginx
1ddb3034d5ade726a221dd5fa4f2a31615d53123ca22af23bbe9862df869140c
[me:~/data/courses]$ docker network inspect my_test_network
[
    {
        "Name": "my_test_network",
        "Id": "8d5303842d31f24e3bc12aa3b5022603d85547a9ee85548a4c01f9a71b7cf840",
        "Created": "2018-06-07T18:15:59.248781591-04:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
                {
                    "Subnet": "172.18.0.0/16",
                    "Gateway": "172.18.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {
            "1ddb3034d5ade726a221dd5fa4f2a31615d53123ca22af23bbe9862df869140c": {
                "Name": "new_nginx",
                "EndpointID": "6630cd38806a8057e9959647f66ad493b927d269bad4fb328cdccbe153713e0b",
                "MacAddress": "02:42:ac:12:00:02",
                "IPv4Address": "172.18.0.2/16",
                "IPv6Address": ""
            }
        },
        "Options": {},
        "Labels": {}
    }
]

# to switch an existing container to a network use network connect
# first showing the hashes for the networks and containers
[me:~/data/courses]$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
dfc440a8cb5d        bridge              bridge              local
406dbffe9820        host                host                local
8d5303842d31        my_test_network     bridge              local
1241cf65cdb7        none                null                local
[me:~/data/courses]$ docker container ls --no-trunc --format 'table {{.ID}}\t{{.Image}}\t{{.Names}}\t{{.Command}}'
CONTAINER ID                                                       IMAGE                   NAMES               COMMAND
1ddb3034d5ade726a221dd5fa4f2a31615d53123ca22af23bbe9862df869140c   nginx                   new_nginx           "nginx -g 'daemon off;'"
c94f8406af1ac0e2a478efb0638d0358c347bed33fe58a9f099eb1b0b59e85fb   landoop/fast-data-dev   eager_rosalind      "/usr/bin/dumb-init -- bash"
ac28cc7a96f1a0ab4ecdd03318f2d95d957edf1d225ed6bb130ba1c705f0d744   landoop/fast-data-dev   gifted_jones        "/usr/bin/dumb-init -- bash"
1e9b894fcb4e895ecd5cbe6057a91878575ca9c3f42eca90972f1b27b4602d8b   landoop/fast-data-dev   lucid_nightingale   "/usr/bin/dumb-init -- /usr/local/bin/setup-and-run.sh"
# now connect the nginx container to the bridge network (network is specified first)
[me:~/data/courses]$ docker network connect dfc440a8cb5d 1ddb3034d5ad
[me:~/data/my-dir]$ docker network inspect bridge
[
    {
        "Name": "bridge",
        "Id": "dfc440a8cb5d3ec0986298ed5ec45e1476d0f85365b00d8113475d788f421355",
        "Created": "2018-06-01T18:28:49.304733642-04:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.17.0.0/16",
                    "Gateway": "172.17.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {
            "1ddb3034d5ade726a221dd5fa4f2a31615d53123ca22af23bbe9862df869140c": {
                "Name": "new_nginx",
                "EndpointID": "73fde8bce61bc3b3909072c58f7112c5131cf43e1c72f84b24dfad041871518e",
                "MacAddress": "02:42:ac:11:00:03",
                "IPv4Address": "172.17.0.3/16",
                "IPv6Address": ""
            },
            "1e9b894fcb4e895ecd5cbe6057a91878575ca9c3f42eca90972f1b27b4602d8b": {
                "Name": "lucid_nightingale",
                "EndpointID": "ffe18c18cdde74bca69f85497a3932edda7c5d3f3438e25be386c13510e62f16",
                "MacAddress": "02:42:ac:11:00:02",
                "IPv4Address": "172.17.0.2/16",
                "IPv6Address": ""
            }
        },
        "Options": {
            "com.docker.network.bridge.default_bridge": "true",
            "com.docker.network.bridge.enable_icc": "true",
            "com.docker.network.bridge.enable_ip_masquerade": "true",
            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",
            "com.docker.network.bridge.name": "docker0",
            "com.docker.network.driver.mtu": "1500"
        },
        "Labels": {}
    }
]
# our container is also still connected to the other network
[me:~/data/my-dir]$ docker network inspect my_test_network
[
    {
        "Name": "my_test_network",
        "Id": "8d5303842d31f24e3bc12aa3b5022603d85547a9ee85548a4c01f9a71b7cf840",
        "Created": "2018-06-07T18:15:59.248781591-04:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
                {
                    "Subnet": "172.18.0.0/16",
                    "Gateway": "172.18.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {
            "1ddb3034d5ade726a221dd5fa4f2a31615d53123ca22af23bbe9862df869140c": {
                "Name": "new_nginx",
                "EndpointID": "6630cd38806a8057e9959647f66ad493b927d269bad4fb328cdccbe153713e0b",
                "MacAddress": "02:42:ac:12:00:02",
                "IPv4Address": "172.18.0.2/16",
                "IPv6Address": ""
            }
        },
        "Options": {},
        "Labels": {}
    }
]
# or inspecting the container and extracting the names shows both virtual networks
[me:~/data/my-dir]$ docker container inspect --format '{{ .NetworkSettings.Networks }}' new_nginx
map[bridge:0xc42046c000 my_test_network:0xc42046c0c0]

# create apps so frontend/backend sit on same docker network
# their intercommunication never leaves host
# all externally exposed ports are closed by default
# you must manually expose via -p, which is better default security
# this gets even better with Swarm and Overlay networks
# with docker network create, you can specify driver with --driver (bridge is default)
# static IP's and using IP's for talking to containers is an anti-pattern
#		overcome this by using Docker DNS - docker has a built in DNS server that containers use by default
# 		docker defaults the hostname to the container's name, but you can also set aliases


# =======================================================================================
# swarm
# =======================================================================================

# swarm mode is a clustering solution built inside docker (can bring together different OS or hosts)
#		* it can be used to scale out or scale up
# not related to swarm classic for pre-1.12 versions, which:
#		was a container that ran inside of docker and took docker run commands and repeated them out to other servers
# added in 1.12 (summer 2016) via swarmkit toolkit
# enhanced in 1.13 (jan 2017) via stacks and secrets
# not enabled by default, new commands once enabled
#		docker swarm
#		docker node
#		docker service	
#			* in a swarm, it replaces a docker run command and allows us to add extra features to container when we run it (e.g. replica) 
#			* these are known as tasks 
#			* a single service can have multiple tasks and each one of those tasks will launch a container
#		docker stack
#		docker secret
# in the concept of swarm, we now have managers and workers - they all communicate over the control plane
#		manager nodes = TLS / Certificate Authority 
#			* a worker with permissions to control the swarm
#			* they all have a database on them known as the raft db and it stores their config and gives them the info they need to have to be an authority
#			* they encrypt their traffic in order to ensure integrity and guarantee their trust so that they can manage the swarm securely
#			* they issue orders down to the workers
#			* they can be demoted down to a worker (or a worker promoted up)
#		worker = TLS
#			* constantly report into the managers and ask for new work

# to tell if swarn is running
[me:~/data/my-dir]$ docker info | grep Swarm
Swarm: inactive

# to create a single node swarm
[me:~/data/my-dir]$ docker swarm init
Swarm initialized: current node (htt0wan0qnk3p41e7sx65waj8) is now a manager.
To add a worker to this swarm, run the following command:
    docker swarm join --token SWMTKN-1-647boq10sfbwj8ftlq0obhm58mo1akyw14ett44rb3hz8bktp7-2mcnrn25z0detq9xx6urr46pr 10.0.2.15:2377
To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
# what just happened?
#		* lots of pki and security automation
#			-- root signing cert created for our swarm
#			-- cert issued for first manager node
#			-- join tokens created
#		* creates raft consensus database to store root CA, configs and secrets
#			-- raft is a protocol that ensures consistency across multiple nodes (ideal in cloud where things go down)
#			-- creates db on disk and encrypts it if on v1.13+
#			-- waits for other manager nodes to be joined to it and then replicates it over to them securely (TLS) - logs too
#			-- don't need an additional key/value system to hold orchestration/secrets (replicated)

# with swarm running, to see the nodes in the swarm (docker node --help)
[me:~/data/my-dir]$ docker node ls
ID                            HOSTNAME                STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
htt0wan0qnk3p41e7sx65waj8 *   localhost.localdomain   Ready               Active              Leader              18.05.0-ce

# docker service in a swarm replaces a docker run
[me:~/data/my-dir]$ docker service --help

# example of giving a simple order (returns the service ID)
[me:~/data/my-dir]$ docker service create alpine ping 8.8.8.8
8iqljmpj3tokkjlghhn0c2gpq
overall progress: 1 out of 1 tasks 
1/1: running   [==================================================>] 
verify: Service converged 

# to see the running services 
[me:~/data/my-dir]$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
8iqljmpj3tok        festive_yalow       replicated          1/1                 alpine:latest  
# to see list of tasks or containers for a service
[me:~/data/my-dir]$ docker service ps festive_yalow
ID                  NAME                IMAGE               NODE                    DESIRED STATE       CURRENT STATE           
4wtep8s8qmz8        festive_yalow.1     alpine:latest       localhost.localdomain   Running             Running 3 minutes ago  
# docker container still works and shows our new task
[me:~/data/my-dir]$ docker container ls --format 'table {{.ID}}\t{{.Image}}\t{{.Names}}'
CONTAINER ID        IMAGE                   NAMES
87c5113bdbf3        alpine:latest           festive_yalow.1.4wtep8s8qmz8414t0yf4kirnm
1ddb3034d5ad        nginx                   new_nginx
c94f8406af1a        landoop/fast-data-dev   eager_rosalind
ac28cc7a96f1        landoop/fast-data-dev   gifted_jones
1e9b894fcb4e        landoop/fast-data-dev   lucid_nightingale

# to scale up a service
[me:~/data/my-dir]$ docker service update 8iqljmpj3tok --replicas 3
8iqljmpj3tok
overall progress: 3 out of 3 tasks 
1/3: running   [==================================================>] 
2/3: running   [==================================================>] 
3/3: running   [==================================================>] 
verify: Service converged 
[me:~/data/my-dir]$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
8iqljmpj3tok        festive_yalow       replicated          3/3                 alpine:latest       
[me:~/data/my-dir]$ docker service ps
[me:~/data/my-dir]$ docker service ps festive_yalow
ID                  NAME                IMAGE               NODE                    DESIRED STATE       CURRENT STATE                ERROR               PORTS
4wtep8s8qmz8        festive_yalow.1     alpine:latest       localhost.localdomain   Running             Running 14 minutes ago                           
pndbgnhz1bpt        festive_yalow.2     alpine:latest       localhost.localdomain   Running             Running about a minute ago                       
wj8eq2qlajsj        festive_yalow.3     alpine:latest       localhost.localdomain   Running             Running about a minute ago
